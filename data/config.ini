[default]
train_pair_file = /var/wqs/conversation-data2/weibo_pair_train.txt
dev_pair_file = /var/wqs/conversation-data2/weibo_pair_dev.txt
test_pair_file = /var/wqs/conversation-data2/weibo_pair_test.txt
post_file = /var/wqs/conversation-data2/weibo.post.txt
response_file = /var/wqs/conversation-data2/weibo.response.txt
black_list_file = ../data/black-list.txt
; pair_file = data/original.pair.txt
check_grad = false
one_response = false
learn_test = false
save_model_per_batch = false
split_unknown_words = false
max_sample_count = 100000000
device_id = 0
output_model_file_prefix = model-
; input_model_file = /home/chncwang/Resources/master-data2-models/model-27-12-2019-12-00-37-epoch0
; input_model_dir = /home/wqs/single-turn-conversation-caf4
program_mode = training
; program_mode = metric
; program_mode = decoding
; program_mode = interacting
; memory_in_gb = 3.0f
; ngram_penalty_1 = 0
; ngram_penalty_2 = 0.2
; ngram_penalty_3 = 0.3
cut_length = 50
result_count_factor = 5

[hyper]
word_dim = 300
hidden_dim = 1024
batch_size = 64
beam_size = 10
dropout = 0.1
learning_rate = 1e-4
min_learning_rate = 1e-3
learning_rate_decay = 1
warm_up_iterations = 0
warm_up_learning_rate = 1e-6
optimzer = adam
word_cutoff = 40
word_file = /var/wqs/sgns.weibo.word
word_finetune = true
l2_reg = 1e-6
